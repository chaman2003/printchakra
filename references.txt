================================================================================
                    PRINTCHAKRA VOICE SYSTEM REFERENCE DOCUMENT
                         Created: December 22, 2025
================================================================================

This document catalogs all voice-related code paths, identifies duplications,
and defines the unified architecture where VOICE = TEXT after STT conversion.

================================================================================
                              ARCHITECTURE SUMMARY
================================================================================

CURRENT STATE (PROBLEMATIC):
  Voice Input → Whisper STT → /voice/process → VoiceChatService.generate_response()
                                              → Backend command parsing
                                              → Backend orchestration logic
                                              → Response with voice_command
                                              
  Text Input  → /voice/chat  → VoiceChatService.generate_response()
              → Frontend AI Assist (parseCommand → handleCommand)
              → Local command execution via callbacks

TARGET STATE (UNIFIED):
  Voice Input → Whisper STT → [TEXT]
                                    ↘
                                      → Frontend AI Assist (parseCommand → handleCommand)
  Text Input  ─────────────────────→   → Local command execution via callbacks
                                      → TTS for voice feedback (optional)

================================================================================
                              FILE INVENTORY
================================================================================

BACKEND VOICE FILES:
─────────────────────────────────────────────────────────────────────────────────
backend/app/modules/voice/__init__.py                    [2176 lines] CORE
  ├── WhisperTranscriptionService                        → KEEP (STT only)
  ├── VoiceChatService                                   → REMOVE (duplicate)
  │   ├── generate_response()                            → DUPLICATE of frontend
  │   ├── interpret_voice_command()                      → DUPLICATE of frontend
  │   ├── _parse_command_parameters()                    → DUPLICATE of frontend
  │   └── _parse_multi_settings_command()                → DUPLICATE of frontend
  ├── VoiceAIOrchestrator                               → SIMPLIFY (STT + TTS only)
  │   ├── process_voice_input()                          → SIMPLIFY to transcribe_only()
  │   ├── _extract_config_parameters()                   → REMOVE (duplicate)
  │   └── speak_text_response()                          → KEEP (TTS)
  └── speak_text_blocking()                              → KEEP (TTS)

backend/app/modules/voice/voice_prompt.py                [675 lines] PROMPTS
  ├── VoicePromptManager                                 → MOSTLY REMOVE
  │   ├── get_system_prompt()                            → REMOVE (LLM not needed)
  │   ├── get_voice_command_mappings()                   → REMOVE (frontend has this)
  │   ├── build_ollama_query()                           → REMOVE (no LLM calls)
  │   ├── format_response()                              → KEEP for TTS formatting
  │   ├── format_response_for_tts()                      → KEEP
  │   ├── get_friendly_command_response()                → MOVE to frontend
  │   ├── is_print_intent() / is_scan_intent()           → REMOVE (frontend has this)
  │   └── is_confirmation() / is_greeting()              → REMOVE (frontend has this)
  └── DEFAULT_COMMAND_CONFIG                             → REMOVE (duplicate)

backend/app/modules/voice/gpu_optimization.py            [360 lines] KEEP ALL
  └── GPU memory management for Whisper                  → KEEP

backend/app/modules/voice/tts_gpu.py                     [250 lines] KEEP ALL
  └── TTS service (SAPI5 fallback)                       → KEEP

─────────────────────────────────────────────────────────────────────────────────
BACKEND ROUTES (app.py):
─────────────────────────────────────────────────────────────────────────────────
Line 4730: /voice/start                                  → KEEP (session init)
Line 4765: /voice/transcribe                             → KEEP (Whisper STT)
Line 4810: /voice/chat                                   → REMOVE (duplicate)
Line 5014: /voice/speak                                  → KEEP (TTS)
Line 5044: /voice/process                                → SIMPLIFY (STT only)
Line 5303: /voice/end                                    → KEEP (session cleanup)
Line 5325: /voice/status                                 → KEEP

NEW ROUTE NEEDED:
  /voice/transcribe-only                                 → STT only, returns text

─────────────────────────────────────────────────────────────────────────────────
BACKEND ORCHESTRATION:
─────────────────────────────────────────────────────────────────────────────────
backend/app/modules/orchestration/__init__.py            [1089 lines]
  ├── detect_intent()                                    → REMOVE (frontend does this)
  ├── parse_voice_configuration()                        → REMOVE (frontend does this)
  ├── map_to_frontend_options()                          → KEEP (response mapping)
  └── process_command()                                  → SIMPLIFY (execute only)

Line 5568: /orchestrate/command                          → SIMPLIFY
Line 6117: /orchestrate/voice-config                     → REMOVE (duplicate)

================================================================================
                              FRONTEND FILES
================================================================================

FRONTEND AI ASSIST (CANONICAL SOURCE OF TRUTH):
─────────────────────────────────────────────────────────────────────────────────
frontend/src/aiassist/types.ts                           [~200 lines] KEEP ALL
  └── All TypeScript types for commands, actions, state

frontend/src/aiassist/config.ts                          [~100 lines] KEEP ALL
  └── Command keywords, thresholds, mappings

frontend/src/aiassist/commandParser.ts                   [854 lines] KEEP ALL
  ├── parseCommand()                                     → MAIN PARSER
  ├── parseCommandWithContext()                          → CONTEXT-AWARE
  ├── parseCommandWithState()                            → STATE MACHINE
  ├── parseDocumentCommand()                             → Document selection
  ├── parsePrintSettingsCommand()                        → Print settings
  ├── parseScanSettingsCommand()                         → Scan settings
  └── parseWorkflowCommand()                             → Workflow actions

frontend/src/aiassist/actionHandler.ts                   [715 lines] KEEP ALL
  ├── handleCommand()                                    → MAIN HANDLER
  ├── handleCommandWithState()                           → STATE-AWARE
  ├── handleDocumentSelection()                          → Document commands
  ├── handleModeSwitch()                                 → Print/scan mode
  ├── handleNavigation()                                 → Scroll, back, next
  └── handleWorkflowAction()                             → Confirm, cancel

frontend/src/aiassist/contextManager.ts                  [450 lines] KEEP ALL
  └── Workflow context state management

frontend/src/aiassist/stateManager.ts                    [617 lines] KEEP ALL
  └── State machine validation

frontend/src/aiassist/documentSelectionParser.ts         [471 lines] KEEP ALL
  └── NL document selection ("select first 3 documents")

frontend/src/aiassist/settingsHandler.ts                 [~200 lines] KEEP ALL
  └── Settings validation and defaults

frontend/src/aiassist/useAIAssist.ts                     [382 lines] KEEP ALL
  ├── processInput()                                     → TEXT ENTRY POINT
  └── processInputWithState()                            → STATE-AWARE ENTRY

frontend/src/aiassist/index.ts                           [55 lines] KEEP ALL
  └── Module exports

─────────────────────────────────────────────────────────────────────────────────
FRONTEND VOICE COMPONENTS:
─────────────────────────────────────────────────────────────────────────────────
frontend/src/components/voice/VoiceAIChat.tsx            [1314 lines] REFACTOR
  CURRENT FLOW (DUPLICATE):
    ├── processAudio() → POST /voice/process → backend parses commands
    └── sendTextMessage() → POST /voice/chat → backend parses commands
  
  TARGET FLOW (UNIFIED):
    ├── processAudio() → POST /voice/transcribe → [TEXT]
    │                                               ↓
    │   ┌───────────────────────────────────────────┘
    │   ↓
    └── handleTextInput(text) → useAIAssist.processInputWithState(text)
                              → Local command execution
                              → POST /voice/speak (optional TTS)

frontend/src/components/voice/VoiceCommandsHelper.tsx    [232 lines] KEEP
  └── UI helper showing available commands

frontend/src/components/voice/utils/voiceAIHelpers.ts    [210 lines] KEEP
  ├── convertToWAV()                                     → Audio conversion
  ├── isValidAudioBlob()                                 → Validation
  ├── sanitizeChatText()                                 → Display formatting
  └── addMessageWithDedup()                              → Message dedup

frontend/src/components/voice/utils/index.ts             [~20 lines] KEEP
  └── Utility exports

frontend/src/components/voice/index.ts                   [~20 lines] KEEP
  └── Component exports

─────────────────────────────────────────────────────────────────────────────────
FRONTEND ORCHESTRATION VOICE:
─────────────────────────────────────────────────────────────────────────────────
frontend/src/components/orchestration/OrchestrationVoiceControl.tsx [594 lines]
  CURRENT FLOW (DUPLICATE):
    ├── processAudio() → POST /voice/process → backend parses
    └── handleTextCommand() → POST /voice/chat → backend parses
    
  TARGET FLOW (UNIFIED):
    ├── processAudio() → POST /voice/transcribe → [TEXT]
    │                                               ↓
    └── executeCommand(text) → parseCommand(text) from aiassist
                             → onCommand callback
                             → POST /voice/speak (optional)

─────────────────────────────────────────────────────────────────────────────────
FRONTEND HOOKS:
─────────────────────────────────────────────────────────────────────────────────
frontend/src/hooks/useVoiceCommandBridge.ts              [517 lines] SIMPLIFY
  CURRENT: Maps backend commands → frontend actions (redundant)
  TARGET:  REMOVE - Not needed when voice uses same flow as text

================================================================================
                              DUPLICATE CODE ANALYSIS
================================================================================

COMMAND PARSING DUPLICATES:
─────────────────────────────────────────────────────────────────────────────────
1. backend/app/modules/voice/__init__.py
   - VoiceChatService.interpret_voice_command()          [~200 lines]
   - DUPLICATES: frontend/src/aiassist/commandParser.ts

2. backend/app/modules/voice/voice_prompt.py
   - VOICE_COMMAND_MAPPINGS                              [~100 lines]
   - DUPLICATES: frontend/src/aiassist/config.ts

3. backend/app/modules/orchestration/__init__.py
   - PrintScanOrchestrator.detect_intent()               [~150 lines]
   - PrintScanOrchestrator.parse_voice_configuration()   [~200 lines]
   - DUPLICATES: frontend/src/aiassist/commandParser.ts

SETTINGS PARSING DUPLICATES:
─────────────────────────────────────────────────────────────────────────────────
1. backend/app/modules/voice/__init__.py
   - VoiceChatService._parse_command_parameters()        [~100 lines]
   - VoiceAIOrchestrator._extract_config_parameters()    [~150 lines]
   - DUPLICATES: frontend/src/aiassist/commandParser.ts (parsePrintSettingsCommand)

2. backend/app/modules/orchestration/__init__.py
   - parse_voice_configuration()                         [~200 lines]
   - DUPLICATES: frontend/src/aiassist/settingsHandler.ts

RESPONSE GENERATION DUPLICATES:
─────────────────────────────────────────────────────────────────────────────────
1. backend/app/modules/voice/voice_prompt.py
   - VoicePromptManager.get_friendly_command_response()  [~100 lines]
   - DUPLICATES: frontend/src/aiassist/actionHandler.ts (responses object)

================================================================================
                              STATE TRANSITIONS
================================================================================

CANONICAL STATE MACHINE (frontend/src/aiassist/stateManager.ts):
─────────────────────────────────────────────────────────────────────────────────

AppState Values:
  DASHBOARD → Starting point, no active workflow
  PRINT_WORKFLOW → Print mode active
  SCAN_WORKFLOW → Scan mode active

PrintWorkflowStep (when AppState = PRINT_WORKFLOW):
  SELECT_DOCUMENT → User selecting documents
  CONFIGURATION → User configuring print settings
  REVIEW → User reviewing before execution
  EXECUTING → Print job running
  COMPLETED → Print job done

ScanWorkflowStep (when AppState = SCAN_WORKFLOW):
  SOURCE_SELECTION → Choose feed tray vs select document
  SELECT_DOCUMENT → User selecting documents (if not feed tray)
  CONFIGURATION → User configuring scan settings
  REVIEW → User reviewing before execution
  EXECUTING → Scan running
  COMPLETED → Scan done

ALLOWED TRANSITIONS:
─────────────────────────────────────────────────────────────────────────────────
DASHBOARD:
  → PRINT_WORKFLOW (on "print" command)
  → SCAN_WORKFLOW (on "scan" command)

PRINT_WORKFLOW.SELECT_DOCUMENT:
  → CONFIGURATION (on document selection complete / "continue")
  → DASHBOARD (on "cancel" with "sorry")
  
PRINT_WORKFLOW.CONFIGURATION:
  → REVIEW (on "continue" / "apply settings")
  → SELECT_DOCUMENT (on "go back")
  → DASHBOARD (on "cancel" with "sorry")

PRINT_WORKFLOW.REVIEW:
  → EXECUTING (on "confirm" / "print")
  → CONFIGURATION (on "go back")
  → DASHBOARD (on "cancel")

SCAN_WORKFLOW follows similar pattern with SOURCE_SELECTION as first step.

================================================================================
                              UNIFIED FLOW DESIGN
================================================================================

SINGLE ENTRY POINT FOR ALL INPUT:
─────────────────────────────────────────────────────────────────────────────────

                    ┌─────────────────┐
                    │   VOICE INPUT   │
                    │  (microphone)   │
                    └────────┬────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │  Whisper STT    │
                    │ POST /voice/    │
                    │   transcribe    │
                    └────────┬────────┘
                             │ returns: { text: string }
                             ▼
              ┌──────────────┴──────────────┐
              │                             │
              ▼                             │
     ┌─────────────────┐                    │
     │   TEXT INPUT    │                    │
     │  (keyboard)     │                    │
     └────────┬────────┘                    │
              │                             │
              └──────────────┬──────────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │   AI ASSIST     │
                    │  parseCommand() │
                    └────────┬────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │  handleCommand  │
                    │  WithState()    │
                    └────────┬────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │   CALLBACKS     │
                    │ onDocumentSelect│
                    │ onSettingsChange│
                    │ onExecute, etc  │
                    └────────┬────────┘
                             │
                             ▼
                    ┌─────────────────┐
                    │   AI RESPONSE   │
                    │  { text, action │
                    │    params }     │
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              │                             │
              ▼                             ▼
     ┌─────────────────┐           ┌─────────────────┐
     │  DISPLAY TEXT   │           │  TTS (optional) │
     │  in chat UI     │           │ POST /voice/speak│
     └─────────────────┘           └─────────────────┘

================================================================================
                              VARIABLE ROUTES
================================================================================

BACKEND ENDPOINTS TO KEEP:
─────────────────────────────────────────────────────────────────────────────────
POST /voice/start
  Input:  { context?: string }
  Output: { success: true, session_id: string }
  
POST /voice/transcribe  (rename from /voice/process for clarity)
  Input:  FormData { audio: Blob }
  Output: { success: true, text: string, language?: string }
  
POST /voice/speak
  Input:  { text: string }
  Output: { success: true, spoken: true }
  
POST /voice/end
  Input:  {}
  Output: { success: true }
  
GET /voice/status
  Output: { session_active: bool, whisper_loaded: bool }

BACKEND ENDPOINTS TO REMOVE:
─────────────────────────────────────────────────────────────────────────────────
POST /voice/chat              → Frontend handles command parsing
POST /voice/process           → Replace with /voice/transcribe (STT only)
POST /orchestrate/voice-config → Frontend handles configuration
POST /orchestrate/command     → Frontend handles via callbacks

─────────────────────────────────────────────────────────────────────────────────
FRONTEND ENTRY POINTS:
─────────────────────────────────────────────────────────────────────────────────
VoiceAIChat.tsx:
  - processAudio(blob)        → calls /voice/transcribe → processTextInput(text)
  - handleTextInput(text)     → calls useAIAssist.processInputWithState(text)

OrchestrationVoiceControl.tsx:
  - processAudio(blob)        → calls /voice/transcribe → executeCommand(text)
  - handleTextCommand()       → calls executeCommand(textInput)
  - executeCommand(text)      → calls parseCommand(text) → onCommand(cmd, params)

Dashboard.tsx:
  - handleVoiceCommand(payload) → already receives parsed command from VoiceAIChat
  - voiceCommandBridge         → REMOVE (no longer needed)

================================================================================
                              EXECUTION FLOW
================================================================================

TEXT INPUT FLOW (CURRENT - KEEP AS-IS):
─────────────────────────────────────────────────────────────────────────────────
1. User types in chat input
2. VoiceAIChat.handleTextInput(text)
3. → useAIAssist.processInputWithState(text)
4.   → parseCommandWithState(text, context)
5.   → handleCommandWithState(command, context, callbacks)
6.   → callbacks.onSelectDocument() / onSettingsChange() / etc.
7. → AIResponse returned
8. → Display response in chat

VOICE INPUT FLOW (TARGET - SIMPLIFIED):
─────────────────────────────────────────────────────────────────────────────────
1. User speaks
2. MediaRecorder captures audio
3. convertToWAV(audioBlob)
4. POST /voice/transcribe with audio
5. Backend: WhisperTranscriptionService.transcribe_audio(audio_data)
6. → returns { success: true, text: "user's spoken text" }
7. Frontend receives text
8. → [MERGE WITH TEXT FLOW AT STEP 2]
9. (Optional) POST /voice/speak with response.text for TTS

================================================================================
                              CALLBACKS MAPPING
================================================================================

AI ASSIST CALLBACKS (useAIAssist.ts):
─────────────────────────────────────────────────────────────────────────────────
onSelectDocument(index, section)      → Select document at index in section
onSelectMultipleDocuments(indices, s) → Select multiple documents
onDeselectDocument(index, section)    → Deselect document
onClearDocumentSelection()            → Clear all selections
onSwitchSection(section)              → Switch to uploads/converted/current
onUpdateSettings(settings)            → Update print/scan settings
onNavigate(direction)                 → next/prev/back navigation
onExecuteAction(action)               → print/scan/cancel/confirm
onFeedDocuments(count)                → Set feed document count
onShowToast(title, desc, status)      → Show toast notification
onModeSwitch(mode, hasSorry)          → Switch print/scan mode
onSetScanSource(source)               → Set scan source (feed/select)
onStateChange(appState, step)         → State machine transition

ORCHESTRATION CALLBACKS (OrchestrationVoiceControl.tsx):
─────────────────────────────────────────────────────────────────────────────────
onCommand(command, params)            → Execute orchestration command
onStepChange(step)                    → Change orchestration step

DASHBOARD CALLBACKS (Dashboard.tsx):
─────────────────────────────────────────────────────────────────────────────────
handleVoiceCommand(payload)           → Process voice command payload
handleVoiceOrchestrationTrigger(mode) → Open orchestration modal

================================================================================
                              FILES TO MODIFY
================================================================================

BACKEND CHANGES:
─────────────────────────────────────────────────────────────────────────────────
backend/app/modules/voice/__init__.py:
  - KEEP: WhisperTranscriptionService (rename transcribe_audio → transcribe)
  - KEEP: speak_text_blocking, _init_tts_engine
  - KEEP: VoiceAIOrchestrator (but simplify - remove command interpretation)
  - CAN REMOVE LATER: VoiceChatService class (when frontend handles all parsing)

backend/app/modules/voice/voice_prompt.py:
  - KEEP: format_response_for_tts() only
  - CAN REMOVE LATER: Command mappings, system prompts (frontend has these)

backend/app.py:
  - KEEP: /voice/start, /voice/end, /voice/status, /voice/speak, /voice/transcribe
  - KEEP: /voice/chat, /voice/process (for backward compatibility)
  - NO CHANGES NEEDED: Existing endpoints work, new unified hook uses /voice/transcribe

FRONTEND CHANGES:
─────────────────────────────────────────────────────────────────────────────────
frontend/src/hooks/useUnifiedVoiceInput.ts:              [NEW - 627 lines]
  - NEW FILE: Unified voice input hook
  - Uses /voice/transcribe for STT only
  - Uses useAIAssist for command parsing (same as text)
  - Optional TTS via /voice/speak

frontend/src/components/voice/VoiceAIChat.tsx:
  - OPTIONAL: Can be refactored to use useUnifiedVoiceInput
  - CURRENT: Works with backend command parsing (voice_command/command_params)
  - MIGRATION: Gradual - can use new hook without breaking existing code

frontend/src/components/orchestration/OrchestrationVoiceControl.tsx:
  - OPTIONAL: Can be refactored to use useUnifiedVoiceInput
  - CURRENT: Uses backend voice_command (modified in previous session)
  - MIGRATION: Gradual - can use new hook for consistent behavior

frontend/src/hooks/useVoiceCommandBridge.ts:
  - KEEP FOR NOW: Some components may still use it
  - DEPRECATE LATER: After migration to useUnifiedVoiceInput complete

frontend/src/pages/Dashboard.tsx:
  - KEEP: handleVoiceCommand callback (works with both approaches)
  - NO CHANGES NEEDED: VoiceAIChat passes commands, Dashboard handles them

================================================================================
                              SUMMARY OF REMOVALS
================================================================================

TOTAL LINES TO REMOVE/SIMPLIFY:
─────────────────────────────────────────────────────────────────────────────────
backend/app/modules/voice/__init__.py   ~1200 lines (VoiceChatService + duplicates)
backend/app/modules/voice/voice_prompt.py ~500 lines (most of file)
backend/app.py /voice/chat route         ~200 lines
backend/app.py /voice/process simplify   ~100 lines  
backend/orchestration duplicate logic    ~350 lines
frontend/useVoiceCommandBridge.ts        ~517 lines (entire file)
frontend/VoiceAIChat.tsx duplicates      ~200 lines
frontend/OrchestrationVoiceControl       ~150 lines

ESTIMATED TOTAL: ~3,200 lines of duplicate/unnecessary code

================================================================================
                              PRESERVED FUNCTIONALITY
================================================================================

WHISPER STT:
  - WhisperTranscriptionService.transcribe_audio() → KEEP
  - GPU optimization for Whisper → KEEP
  - Audio validation → KEEP

TTS:
  - speak_text_blocking() → KEEP
  - SAPI5 fallback → KEEP
  - format_response_for_tts() → KEEP

FRONTEND AI ASSIST:
  - All of frontend/src/aiassist/ → KEEP (this is the source of truth)
  - parseCommand(), handleCommand() → KEEP
  - State machine → KEEP
  - Document selection parser → KEEP

UI COMPONENTS:
  - VoiceAIChat.tsx chat UI → KEEP (refactor internal flow)
  - VoiceCommandsHelper.tsx → KEEP
  - OrchestrationVoiceControl.tsx → KEEP (refactor internal flow)

================================================================================
                              END OF DOCUMENT
================================================================================

================================================================================
                         UNIFIED VOICE IMPLEMENTATION
                             (NEW ARCHITECTURE)
================================================================================

UNIFIED HOOK: frontend/src/hooks/useUnifiedVoiceInput.ts
─────────────────────────────────────────────────────────────────────────────────

PURPOSE:
  Single hook that provides voice input with IDENTICAL flow to text input.
  Voice differs ONLY in input source (Whisper STT vs keyboard).

USAGE:
  ```tsx
  import { useUnifiedVoiceInput } from '../hooks';

  const {
    isSessionActive,
    isRecording,
    isProcessing,
    isSpeaking,
    startSession,
    endSession,
    startRecording,
    stopRecording,
    processTextInput,  // Can also process text (same flow!)
    context,
  } = useUnifiedVoiceInput({
    enableTTS: true,
    onDocumentSelect: (idx, section) => selectDocument(idx, section),
    onSettingsChange: (settings) => updateSettings(settings),
    onExecute: (action) => handleAction(action),
    onStateChange: (state, step) => handleState(state, step),
    onTranscription: (text) => addMessage('user', text),
    onAIResponse: (response) => addMessage('ai', response.text),
  });
  ```

FLOW:
  1. Voice: startRecording() → audio → /voice/transcribe → text → processTextInput()
  2. Text: processTextInput(text) → useAIAssist.processInputWithState() → response
  3. Both flows use IDENTICAL parsing via frontend/src/aiassist/commandParser.ts

KEY EXPORTS:
  - useUnifiedVoiceInput: Main hook function
  - UnifiedVoiceInputOptions: Options interface (extends UseAIAssistOptions)
  - UnifiedVoiceInputReturn: Return interface

BACKEND DEPENDENCY:
  - POST /voice/start: Initialize Whisper model
  - POST /voice/transcribe: STT only (returns { success, text })
  - POST /voice/speak: TTS (optional, for voice feedback)
  - POST /voice/end: Cleanup session

NO BACKEND COMMAND PARSING:
  - /voice/chat is NOT used (frontend parses commands)
  - /voice/process is NOT used (only /voice/transcribe for STT)
  - Backend voice_command/command_params NOT used (frontend aiassist handles)

================================================================================
                         MIGRATION GUIDE
================================================================================

FROM OLD (VoiceAIChat with backend parsing):
─────────────────────────────────────────────────────────────────────────────────
OLD:
  // VoiceAIChat.tsx
  const response = await apiClient.post('/voice/process', formData);
  const { voice_command, command_params, ai_response } = response.data;
  onVoiceCommand?.({ command: voice_command, params: command_params });

NEW:
  // Using useUnifiedVoiceInput
  const { processTextInput, onTranscription } = useUnifiedVoiceInput({
    onDocumentSelect: handleDocSelect,
    onSettingsChange: handleSettings,
    // ... all callbacks same as useAIAssist
  });
  
  // After STT:
  onTranscription(text); // Show what user said
  const response = processTextInput(text); // Same as text input!
  // Response has: { text, action, params, handled, success }

FROM OLD (useVoiceCommandBridge):
─────────────────────────────────────────────────────────────────────────────────
OLD:
  // Dashboard.tsx
  const voiceCommandBridge = useVoiceCommandBridge({
    orchestrateOptions,
    onOptionsChange,
    documentSelectorRef,
    // ... lots of props
  });
  voiceCommandBridge.handleVoiceCommand(payload); // Maps backend command

NEW:
  // No bridge needed! VoiceAIChat uses same callbacks as text AI assist
  <VoiceAIChat
    onDocumentSelect={handleDocSelect}
    onSettingsChange={handleSettings}
    onExecute={handleExecute}
    // Same callbacks, no bridge translation needed
  />

================================================================================
                         BENEFITS OF UNIFIED APPROACH
================================================================================

1. SINGLE SOURCE OF TRUTH
   - All command parsing in frontend/src/aiassist/
   - No duplicate parsing in backend
   - Same behavior for voice and text

2. REDUCED CODE
   - ~3000 lines of duplicate backend code can be removed
   - useVoiceCommandBridge (517 lines) no longer needed
   - Voice prompt manager command mappings not needed

3. FASTER ITERATION
   - Add new command once in frontend
   - Works for both voice and text automatically
   - No backend deployment for command changes

4. CONSISTENT RESPONSES
   - Same response messages for voice and text
   - State machine validation in one place
   - Error handling unified

5. SIMPLER DEBUGGING
   - One flow to trace
   - Frontend devtools for all command parsing
   - No network-related parsing issues

